from data.song import Song
from music21 import roman, stream, note
from src.utils import get_project_root
from keras.models import model_from_json
import json
import numpy
from keras.utils import np_utils
import copy
ROOT_DIR = get_project_root()


def load_model(model_name, model_type):
	modelFile = ROOT_DIR + '/files/models/' + model_type + '/model_' + model_name + '.json'
	weightFile = ROOT_DIR + '/files/models/' + model_type + '/weights_' + model_name + '.h5'

	# load json and create model
	json_file = open(model_file, 'r')
	loaded_model_json = json_file.read()
	json_file.close()
	loaded_model = model_from_json(loaded_model_json)

	# load weights into new model
	loaded_model.load_weights(weight_file)

	return loaded_model


def convert_notes(inputs, note_map):
	notes = []
	for input in inputs:
		idx = numpy.argmax(input)
		result = list(note_map.keys())[list(note_map.values()).index(idx)]
		notes.append(result)
	return notes


def convert_duration(durations, duration_map):
	durs = []
	for input in durations:
		idx = numpy.argmax(input)
		result = list(duration_map.keys())[list(duration_map.values()).index(idx)]
		durs.append(result)
	return durs


def load_mapping(harmony_model_name, duration_model_name):
	harmony_map =  json.loads(open(ROOT_DIR + '/files/mappings/' + harmony_model_name + '_harmony.json').read())
	duration_map = json.loads(open(ROOT_DIR + '/files/mappings/' + duration_model_name + '_durations.json').read())
	return harmony_map, duration_map

def check_duration(duration_val, duration_map, generated_durations):

	#idx = 
	#benchmark = sum(generatedDurations) % 4 
	#newBenchmark = (sum(generatedDurations) + newDuration) % 4
	#if newBenchmark > benchmark
	idx = numpy.argmax(duration_val)

	duration = list(duration_map.keys())[list(duration_map.values()).index(idx)]
	return duration



def write_midi(generated_harmony, generated_durations, key, song_name):
	offset = 0
	output_chords = []
	output_notes = []
	# create note and chord objects based on the values generated by the model
	for i, nt in enumerate(generated_harmony):
		rn = roman.RomanNumeral(nt, key)

		gen_note = None
		if i == 0:
			gen_note = note.Note()
			gen_note.pitch = rn.pitches[0]
		else:
			gen_note = note.Note()
			gen_note.pitch = get_best_note(rn.pitches, output_chords[-1])

		# pattern is a chord
	#	new_chord = chord.Chord(rn.pitches)
		gen_note.offset = offset
		gen_note.duration.quarterLength = float(generated_durations[i])
		output_notes.append(gen_note)
		output_chords.append(rn.pitches)
		offset = offset + float(generated_durations[i])

		# increase offset each iteration so that notes do not stack
		#duration = choice(durationOptions, 1, p=durationProbs)

	midi_stream = stream.Stream(output_notes)
	save_file = ROOT_DIR + '/files/songs/' + song_name

	midi_stream.write('midi', fp=save_file)


def get_best_note(pitches, last_pitches):
	new_chord_ps = [pitch.ps for pitch in pitches]
	old_chord_ps = [pitch.ps for pitch in last_pitches]

	dif_indices = []
	for i in len(new_chord_ps):
		if new_chord_ps[i] != old_chord_ps[i]:
			dif_indices.append(i)
	
	if len(dif_indices) == 0:
		#lastPs = lastNote.ps
		return pitches[0]
	else:
		return pitches[numpy.random.choice(dif_indices)]


def generate_start_sequence(sequence_len, mapping):
	start = []
	n_options = len(mapping)
	for i in range(sequence_len):
		start.append(numpy.random.choice(n_options))
	start = np_utils.to_categorical(start, num_classes=len(mapping))
	return start


def generate(duration_model_name, harmony_model_name, n_notes, key, sequence_len, song_name):
	harmony_model = load_model(harmony_model_name, 'harmony')
	duration_model = load_model(duration_model_name, 'duration')

	note_map, duration_map  = load_mapping(harmony_model_name, duration_model_name)

	harmony_start = generate_start_sequence(sequence_len, note_map)
	duration_start = generate_start_sequence(sequence_len, duration_map)

	harmony_sequence = numpy.reshape(harmony_start, (1, sequence_len, len(note_map)))
	duration_sequence = numpy.reshape(duration_start, (1, sequence_len, len(duration_map)))

	generated_harmony = convert_notes(harmony_sequence, noteMap)
	generated_duration = convert_duration(duration_sequence, duration_map)

	for note in range(n_notes):
		harmonic_input = copy.deepcopy(harmony_sequence)
		harmony_val = harmonyModel.predict(harmony_sequence, verbose=0)
		harmony_idx = numpy.argmax(harmony_val)

		harmony = list(note_map.keys())[list(note_map.values()).index(harmony_idx)]
		generated_harmony.append(harmony)

		#process harmony
		next_harmony =  np_utils.to_categorical([harmony_idx], num_classes=len(note_map))
		next_harmony = numpy.reshape(next_harmony, (1, 1, len(note_map)))
		next_harmony = next_harmony/len(note_map)
		harmony_sequence = numpy.concatenate((harmony_sequence, next_harmony), axis = 1)
		harmony_sequence = numpy.delete(harmony_sequence, 0, axis=1)

		#process duration

		duration_input = copy.deepcopy(duration_sequence)
		duration_val = duration_model.predict(duration_sequence, verbose=0)

		duration = checkDuration(duration_val, duration_map, generated_duration)
		generated_duration.append(duration)
		next_duration =  np_utils.to_categorical([duration_map[duration]], num_classes=len(duration_map))
		next_duration = numpy.reshape(next_duration, (1, 1, len(duration_map)))
		next_duration = next_duration/len(duration_map)
		duration_sequence = numpy.concatenate((duration_sequence, next_duration), axis = 1)
		duration_sequence = numpy.delete(duration_sequence, 0, axis=1)

	output = write_midi(generated_harmony, generated_duration, key, song_name)

	return output


if __name__ == '__main__':
	duration_model_name = 'allTest_duration'
	harmony_model_name =  'allTest_harmony'
	n_notes = 300
	key = 'D'
	sequence_len = 24
	song_name = 'hello1.mid'
	generate(duration_model_name, harmony_model_name, n_notes, key, sequence_len, song_name)













